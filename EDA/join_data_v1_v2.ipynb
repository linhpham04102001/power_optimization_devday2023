{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cognitive-bread",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "coupled-collect",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "straight-trauma",
   "metadata": {},
   "source": [
    "### 1. solar power generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "following-representative",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file = pd.ExcelFile(f\"../raw data/2023_devday_data-20230320T123236Z-001/2023_devday_data/v{v}/realne_report_solar_30_v0000{v}_20220301_20230228.xlsx\")\n",
    "\n",
    "data = pd.DataFrame()\n",
    "\n",
    "# Loop through all sheets in the Excel file\n",
    "for sheet_name in excel_file.sheet_names:\n",
    "    # Load the sheet as a DataFrame\n",
    "    df = excel_file.parse(sheet_name)\n",
    "    \n",
    "    # Add a new column to the DataFrame\n",
    "    df[\"new_column_name\"] = sheet_name\n",
    "    columns = list(df.loc[4].values[:-1])\n",
    "    columns.append('date')\n",
    "    \n",
    "    df.drop([0,1,2,3,4],inplace=True)\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    df.columns = columns\n",
    "    df.date = pd.to_datetime(df.date + ' ' + df.時刻, format=\"%Y-%m-%d %H:%M\")\n",
    "    df.drop('時刻', axis=1, inplace=True)\n",
    "    data = pd.concat([data, df])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "royal-border",
   "metadata": {},
   "source": [
    "## 2. power consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "intense-samoa",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file1 = pd.ExcelFile(f\"../raw data/2023_devday_data-20230320T123236Z-001/2023_devday_data/v{v}/realne_report_surplus30p_v0000{v}_20220301_20221231.xlsx\")\n",
    "\n",
    "surplus_data = pd.DataFrame()\n",
    "\n",
    "# Loop through all sheets in the Excel file\n",
    "for sheet_name in excel_file1.sheet_names:\n",
    "    # Load the sheet as a DataFrame\n",
    "    df = excel_file1.parse(sheet_name)\n",
    "    \n",
    "    # Add a new column to the DataFrame\n",
    "    df[\"new_column_name\"] = sheet_name\n",
    "    columns = list(df.loc[4].values[:-1])\n",
    "    columns.append('date')\n",
    "    \n",
    "    df.drop([0,1,2,3,4],inplace=True)\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    df.columns = columns\n",
    "    df.date = pd.to_datetime(df.date + ' ' + df.時刻, format=\"%Y-%m-%d %H:%M\")\n",
    "    df.drop('時刻', axis=1, inplace=True)\n",
    "    surplus_data = pd.concat([surplus_data, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "placed-board",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file2 = pd.ExcelFile(f\"../raw data/2023_devday_data-20230320T123236Z-001/2023_devday_data/v{v}/realne_report_surplus30p_v0000{v}_20230101_20230228.xlsx\")\n",
    "\n",
    "# Loop through all sheets in the Excel file\n",
    "for sheet_name in excel_file2.sheet_names:\n",
    "    # Load the sheet as a DataFrame\n",
    "    df = excel_file2.parse(sheet_name)\n",
    "    \n",
    "    # Add a new column to the DataFrame\n",
    "    df[\"new_column_name\"] = sheet_name\n",
    "    columns = list(df.loc[4].values[:-1])\n",
    "    columns.append('date')\n",
    "    \n",
    "    df.drop([0,1,2,3,4],inplace=True)\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    df.columns = columns\n",
    "    df.date = pd.to_datetime(df.date + ' ' + df.時刻, format=\"%Y-%m-%d %H:%M\")\n",
    "    df.drop('時刻', axis=1, inplace=True)\n",
    "    surplus_data = pd.concat([surplus_data, df])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smooth-stick",
   "metadata": {},
   "source": [
    "## 3. cloud "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "exclusive-antigua",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1_cloud = pd.read_csv(f\"../raw data/2023_devday_data-20230320T123236Z-001/2023_devday_data/v{v}/cloud_v0000{v}.csv\")\n",
    "v1_cloud.index = pd.to_datetime(v1_cloud.target_date)\n",
    "v1_cloud.drop(['execution_date','target_date'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "duplicate-slave",
   "metadata": {},
   "source": [
    "## 4. solar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "improving-integrity",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1_solar = pd.read_csv(f\"../raw data/2023_devday_data-20230320T123236Z-001/2023_devday_data/v{v}/solar_v0000{v}.csv\")\n",
    "v1_solar.index = pd.to_datetime(v1_solar.target_date)\n",
    "v1_solar.drop(['execution_date','target_date'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indian-turkey",
   "metadata": {},
   "source": [
    "## 5. weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "foster-cancer",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1_weather = pd.read_csv(f\"../raw data/2023_devday_data-20230320T123236Z-001/2023_devday_data/v{v}/weather_forecast_v0000{v}.csv\")\n",
    "v1_weather.index = pd.to_datetime(v1_weather.target_date)\n",
    "v1_weather.drop(['execution_date','target_date'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relevant-behalf",
   "metadata": {},
   "source": [
    "## 6. merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "statewide-plaza",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values(by='date',inplace=True)\n",
    "surplus_data.sort_values(by='date',inplace=True)\n",
    "final_v1 = pd.merge(data, surplus_data, how='outer', on='date')\n",
    "final_v1.index = final_v1.date\n",
    "final_v1 = final_v1.tz_localize('Japan')\n",
    "\n",
    "v1_cloud = v1_cloud.tz_convert('Japan')\n",
    "v1_solar = v1_solar.tz_convert('Japan')\n",
    "v1_weather = v1_weather.tz_convert('Japan')\n",
    "\n",
    "final_v1 = pd.merge(final_v1, v1_cloud, how='outer', left_index=True, right_index=True)\n",
    "final_v1 = pd.merge(final_v1, v1_solar, how='outer', left_index=True, right_index=True)\n",
    "final_v1 = pd.merge(final_v1, v1_weather, how='outer', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boring-hanging",
   "metadata": {},
   "source": [
    "## 7. save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "standing-quarterly",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_v1.to_csv(f'v{v}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pDL] *",
   "language": "python",
   "name": "conda-env-pDL-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
